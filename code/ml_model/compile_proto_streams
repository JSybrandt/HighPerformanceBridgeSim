#!/usr/bin/env python3
from result_pb2 import Trial
import stream  # proto stream
from glob import glob
from multiprocessing import Pool
from random import shuffle
import numpy as np
from pathlib import Path
from argparse import ArgumentParser
import pickle
from tqdm import tqdm
from functools import partial
from multiprocessing import current_process

DISABLE_PBAR=False

def parse_args():
  parser = ArgumentParser()
  parser.add_argument("in_dir", type=Path)
  parser.add_argument("out_path", type=Path)
  parser.add_argument("--validation_ratio", type=float, default=0.1)
  parser.add_argument("--test_ratio", type=float, default=0.2)
  parser.add_argument("--data_per_day", type=int)
  parser.add_argument("--target_type", choices=["classification", "regression"], default="classification")
  return parser.parse_args()

def to_sequence(trial):
  sequence = []
  seq_length = len(trial.fft.upper_amp)
  assert seq_length == len(trial.fft.lower_amp)
  assert seq_length > 0
  band_pass_step = (trial.fft.band_pass_end - trial.fft.band_pass_start) \
                 / seq_length
  for idx, freq in enumerate(np.arange(trial.fft.band_pass_start,
                                       trial.fft.band_pass_end,
                                       band_pass_step)):
    sequence.append([trial.time_of_day,
                     trial.vehicle.mass,
                     trial.vehicle.speed,
                     trial.temperature,
                     freq,
                     trial.fft.upper_amp[idx],
                     trial.fft.lower_amp[idx]])
  return sequence

def load_stream(stream_path, target_type, data_per_day):
  res = []
  #try:
  with stream.open(str(stream_path), 'rb') as proto_stream:
    for idx, data in enumerate(tqdm(proto_stream,
                                    position=current_process()._identity[0],
                                    disable=DISABLE_PBAR)):
      trial = Trial()
      trial.ParseFromString(data)
      if target_type == "classification":
        assert trial.HasField("damage_class")
        target = trial.damage_class
      if target_type == "regression":
        assert trial.HasField("damage_amount")
        target = trial.damage_amount
      res.append({'x': to_sequence(trial),
                  'y': target,
                  'day': trial.day})
      if data_per_day is not None and num_complete >= data_per_day:
        break
  #except:
  #  print("TOTAL FILE ERROR:", stream_path)
  return res

def get_empty_output_dict():
  return {
      "train": [],
      "test": [],
      "validation": []
    }

def random_split(unsorted_data,validation_ratio, test_ratio):
  output = get_empty_output_dict()
  shuffle(unsorted_data)
  train_cutoff = int(len(unsorted_data) * (1 - validation_ratio - test_ratio))
  validation_cutoff = int(train_cutoff + len(unsorted_data)*validation_ratio)
  assert train_cutoff > 0
  assert validation_cutoff >= train_cutoff
  output["train"] = unsorted_data[:train_cutoff]
  output["validation"] = unsorted_data[train_cutoff:validation_cutoff]
  output["test"] = unsorted_data[validation_cutoff:]
  return output

if __name__=="__main__":
  args = parse_args()
  print(args)
  stream_paths = list(args.in_dir.glob("*.proto_stream"))
  assert len(stream_paths) > 0
  print("Found", len(stream_paths))
  assert not args.out_path.exists() and args.out_path.parent.is_dir()

  load_fn = partial(load_stream,
                    target_type=args.target_type,
                    data_per_day=args.data_per_day)

  split_fn = partial(random_split,
                     validation_ratio=args.validation_ratio,
                     test_ratio=args.test_ratio)

  print("Starting")

  data_labels = []
  with Pool() as pool:
    for res in tqdm(pool.imap(load_fn, stream_paths),
                              total=len(stream_paths),
                              disable=DISABLE_PBAR):
      data_labels += res

  output = split_fn(data_labels)
  output["description"] = str(args)
  with open(args.out_path, 'wb') as pfile:
    pickle.dump(output, pfile)
